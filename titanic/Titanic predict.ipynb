{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The real\n",
    "\n",
    "This notebook is to serve as a full compareson of model using better feature extraction.  We will extract surnames, an interaction between age and fare, and the total family size and run  the set of features on different models and compare the difference.  We will compare decision trees and Adaboost with decision tree stumps since they performed better in our pocs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import linear_model\n",
    "import features\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv('../data/train.csv', header=0)\n",
    "test_raw = pd.read_csv('../data/test.csv', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that the test set does not have any missing data we have to deal with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_raw) - test_raw.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw['is_train'] = 1\n",
    "test_raw['is_train'] = 0\n",
    "data_raw = pd.concat([train_raw, test_raw])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "\n",
    "We will create a surname feature and a family size feature and then run it all through the preprocessing script. After will will add an interaction term between fare and age.  This need to happen after the script due to missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_raw['Fam_size'] = data_raw['SibSp'] + data_raw['Parch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr.                          517\n",
       "Miss.                        182\n",
       "Mrs.                         124\n",
       "Master.                       40\n",
       "Dr.                            7\n",
       "Rev.                           6\n",
       "Major.                         2\n",
       "Col.                           2\n",
       "Mlle.                          2\n",
       "Ms.                            1\n",
       "Don.                           1\n",
       "Capt.                          1\n",
       "Sir.                           1\n",
       "Lady.                          1\n",
       "the Countess.                  1\n",
       "Mrs. Martin (Elizabeth L.      1\n",
       "Jonkheer.                      1\n",
       "Mme.                           1\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw['Name'].str.extract('(,\\s)(.*\\.)', expand=False)[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titles = ['Mr.', 'Miss.', 'Mrs.', 'Master.']\n",
    "data_raw['Surname'] = data_raw['Name'].str.extract('(,\\s)(.*\\.)', expand=False)[1]\n",
    "data_raw.loc[~data_raw['Surname'].isin(titles),'Surname'] = 'Rare'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_features = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked', 'Fam_size', 'Surname']\n",
    "numerical_features = ['Age', 'Fare']\n",
    "target = 'Survived'\n",
    "data_clean, y = features.decision_tree_preprocessing(data_raw, \n",
    "                                                  target,\n",
    "                                                  categorical_features=categorical_features, \n",
    "                                                  numerical_features=numerical_features, \n",
    "                                                  drop_na_columns=['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_clean['AgeXFare'] = data_clean['Age'] * data_clean['Fare']\n",
    "X = data_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the models\n",
    "\n",
    "**TODO** : use a grid search to tune the hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_ada = ensemble.AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth=2))\n",
    "model_tree = tree.DecisionTreeClassifier(max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_ada = cross_val_score(model_ada, X, y, cv=10)\n",
    "scores_tree = cross_val_score(model_tree, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost accuracy: 0.82 (+/- 0.07)\n",
      "Decision tree accuracy: 0.81 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "print(\"AdaBoost accuracy: %0.2f (+/- %0.2f)\" % (scores_ada.mean(), scores_ada.std() * 2))\n",
    "print(\"Decision tree accuracy: %0.2f (+/- %0.2f)\" % (scores_tree.mean(), scores_tree.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
